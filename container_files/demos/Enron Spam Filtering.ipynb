{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Spam Filtering Using [Euron's Dataset][1] - PART 1\n",
    "[1]: [http://www.aueb.gr/users/ion/data/enron-spam/]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from pymldb import Connection\n",
    "mldb = Connection('http://localhost/')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First let's load the 1st of Enron's datasets (there are 6) into MDLB, using a separate script."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<strong>POST http://localhost/v1/datasets/enron_data/commit</strong><br /><strong style=\"color: green;\">200 OK</strong><br /> "
      ],
      "text/plain": [
       "<Response [200]>"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mldb.put('/v1/datasets/enron_data', {'type': 'sparse.mutable'})\n",
    "%run -n load_enron.py\n",
    "add_enron_file_to_dataset(mldb, '/v1/datasets/enron_data', 1)\n",
    "mldb.post('/v1/datasets/enron_data/commit')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is what the dataset looks like.\n",
    "\n",
    "*index*: order in which the emails arrived in the user's inbox  \n",
    "*msg*: actual content of the email  \n",
    "*label*: was the email legitimate (*ham*) or not (*spam*)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index</th>\n",
       "      <th>msg</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>_rowName</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>enron_1_mail_0</th>\n",
       "      <td>0</td>\n",
       "      <td>Subject: dobmeos with hgh my energy level has ...</td>\n",
       "      <td>spam</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>enron_1_mail_1</th>\n",
       "      <td>1</td>\n",
       "      <td>Subject: christmas tree farm pictures\\n</td>\n",
       "      <td>ham</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>enron_1_mail_2</th>\n",
       "      <td>2</td>\n",
       "      <td>Subject: vastar resources , inc .\\ngary , prod...</td>\n",
       "      <td>ham</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>enron_1_mail_3</th>\n",
       "      <td>3</td>\n",
       "      <td>Subject: calpine daily gas nomination\\n- calpi...</td>\n",
       "      <td>ham</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>enron_1_mail_4</th>\n",
       "      <td>4</td>\n",
       "      <td>Subject: re : issue\\nfyi - see note below - al...</td>\n",
       "      <td>ham</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>enron_1_mail_5</th>\n",
       "      <td>5</td>\n",
       "      <td>Subject: meter 7268 nov allocation\\nfyi .\\n- -...</td>\n",
       "      <td>ham</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>enron_1_mail_6</th>\n",
       "      <td>6</td>\n",
       "      <td>Subject: your prescription is ready . . oxwq s...</td>\n",
       "      <td>spam</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>enron_1_mail_7</th>\n",
       "      <td>7</td>\n",
       "      <td>Subject: mcmullen gas for 11 / 99\\njackie ,\\ns...</td>\n",
       "      <td>ham</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>enron_1_mail_8</th>\n",
       "      <td>8</td>\n",
       "      <td>Subject: meter 1517 - jan 1999\\ngeorge ,\\ni ne...</td>\n",
       "      <td>ham</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>enron_1_mail_9</th>\n",
       "      <td>9</td>\n",
       "      <td>Subject: duns number changes\\nfyi\\n- - - - - -...</td>\n",
       "      <td>ham</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                index                                                msg label\n",
       "_rowName                                                                      \n",
       "enron_1_mail_0      0  Subject: dobmeos with hgh my energy level has ...  spam\n",
       "enron_1_mail_1      1            Subject: christmas tree farm pictures\\n   ham\n",
       "enron_1_mail_2      2  Subject: vastar resources , inc .\\ngary , prod...   ham\n",
       "enron_1_mail_3      3  Subject: calpine daily gas nomination\\n- calpi...   ham\n",
       "enron_1_mail_4      4  Subject: re : issue\\nfyi - see note below - al...   ham\n",
       "enron_1_mail_5      5  Subject: meter 7268 nov allocation\\nfyi .\\n- -...   ham\n",
       "enron_1_mail_6      6  Subject: your prescription is ready . . oxwq s...  spam\n",
       "enron_1_mail_7      7  Subject: mcmullen gas for 11 / 99\\njackie ,\\ns...   ham\n",
       "enron_1_mail_8      8  Subject: meter 1517 - jan 1999\\ngeorge ,\\ni ne...   ham\n",
       "enron_1_mail_9      9  Subject: duns number changes\\nfyi\\n- - - - - -...   ham"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mldb.query('select index, msg, label from enron_data order by index limit 10')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's create a *sql.expression* that will simply tokenize the emails into a bag of words. Those will be our features on which we will train a classifier."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<Response [201]>\n"
     ]
    }
   ],
   "source": [
    "print mldb.put('/v1/functions/bow', {\n",
    "    'type': 'sql.expression',\n",
    "    'params': {\n",
    "        'expression': \"\"\"\n",
    "            tokenize(msg, {splitchars: ' \\n', quotechar: ''}) as bow\n",
    "            \"\"\"\n",
    "    }\n",
    "})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then we can generate the features for the whole dataset, and write them into a new dataset, using the *transform* procedure."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<Response [201]>\n"
     ]
    }
   ],
   "source": [
    "print mldb.put('/v1/procedures/generate_feats', {\n",
    "    'type': 'transform',\n",
    "    'params': {\n",
    "        'inputData': \"\"\"\n",
    "            select bow({msg:msg}) as features, label = 'spam' as label\n",
    "            from enron_data\n",
    "            \"\"\",\n",
    "        'outputDataset': 'enron_features',\n",
    "        'runOnCreation': True\n",
    "    }\n",
    "})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, let's train a very simple classifier, by training on the first half of the messages, and testing on the second half. This classifier will give a score to every email, and we can then choose a threshold where everything above the threshold is classified as spam, and every thing below as ham."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<Response [201]>\n"
     ]
    }
   ],
   "source": [
    "n = mldb.get('/v1/query', q='select count(*) as n from enron_features',\n",
    "             format='aos').json()[0]['n']\n",
    "res = mldb.put('/v1/procedures/experiment', {\n",
    "    'type': 'classifier.experiment',\n",
    "    'params': {\n",
    "        'experimentName': 'enron_experiment1',\n",
    "        'trainingData': 'select {features.*} as features, label from enron_features',\n",
    "        # for now 50/50 split in time, but we might do something more\n",
    "        # fancy later!\n",
    "        'datasetFolds': [{\n",
    "            'training_limit': n // 2,\n",
    "            'testing_offset': n // 2,\n",
    "            'orderBy': 'index',\n",
    "        }],\n",
    "        'modelFileUrlPattern': 'file://enron_model_$runid.cls',\n",
    "        'algorithm': 'dt',\n",
    "        'runOnCreation': True\n",
    "    }\n",
    "})\n",
    "print res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AUC = 0.9575486565\n"
     ]
    }
   ],
   "source": [
    "print 'AUC =', res.json()['status']['firstRun']['status']['aggregated']['auc']['mean']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Not a bad AUC for a model that simple. But [the AUC score of a classifier is only a very generic measure of performance][1]. When having a specific problem like spam filtering, we're better off using a performance metric that matches our intuition about what a good spam filter is. Namely, a good spam filtering algorithm should almost never flag as spam a legitime email, while keeping your inbox as spam-free as possible. This is what should be used to choose the threshold for the classifier, and then to measure its performance.\n",
    "\n",
    "So instead of the AUC (that doesn't pick a specific threshold but uses all of them), let's use as our performance metric the best [$F_{0.05}$ score][2], which gives 20 times more importance to precision than recall. In other words, this metric represents the fact that classifying as spam **only** what is really spam is 20 times more important than finding all the spam.\n",
    "\n",
    "Let's see how our we are doing with that metric.\n",
    "[1]: http://mldb.ai/blog/posts/2016/01/ml-meets-economics/\n",
    "[2]: https://en.wikipedia.org/wiki/F1_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<Response [201]>\n"
     ]
    }
   ],
   "source": [
    "print mldb.put('/v1/functions/enron_score', {\n",
    "    'type': 'sql.expression',\n",
    "    'params': {\n",
    "        'expression': \"\"\"\n",
    "            (1 + pow(.05, 2)) * (precision * recall) / (precision * pow(.05, 2) + recall) as score\n",
    "            \"\"\"\n",
    "    }\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>truePositives</th>\n",
       "      <th>trueNegatives</th>\n",
       "      <th>falsePositives</th>\n",
       "      <th>falseNegatives</th>\n",
       "      <th>precision</th>\n",
       "      <th>recall</th>\n",
       "      <th>score</th>\n",
       "      <th>cost</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>_rowName</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>enron_1_mail_5044</th>\n",
       "      <td>155</td>\n",
       "      <td>3672</td>\n",
       "      <td>0</td>\n",
       "      <td>1345</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.103333</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.978819</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>enron_1_mail_4637</th>\n",
       "      <td>447</td>\n",
       "      <td>3661</td>\n",
       "      <td>11</td>\n",
       "      <td>1053</td>\n",
       "      <td>0.975983</td>\n",
       "      <td>0.298000</td>\n",
       "      <td>0.976489</td>\n",
       "      <td>0.970476</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>enron_1_mail_531</th>\n",
       "      <td>492</td>\n",
       "      <td>3657</td>\n",
       "      <td>15</td>\n",
       "      <td>1008</td>\n",
       "      <td>0.970414</td>\n",
       "      <td>0.328000</td>\n",
       "      <td>0.946242</td>\n",
       "      <td>0.965698</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>enron_1_mail_3366</th>\n",
       "      <td>501</td>\n",
       "      <td>3656</td>\n",
       "      <td>16</td>\n",
       "      <td>999</td>\n",
       "      <td>0.969052</td>\n",
       "      <td>0.334000</td>\n",
       "      <td>0.933693</td>\n",
       "      <td>0.964479</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>enron_1_mail_4542</th>\n",
       "      <td>643</td>\n",
       "      <td>3628</td>\n",
       "      <td>44</td>\n",
       "      <td>857</td>\n",
       "      <td>0.935953</td>\n",
       "      <td>0.428667</td>\n",
       "      <td>0.888078</td>\n",
       "      <td>0.933199</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>enron_1_mail_5043</th>\n",
       "      <td>711</td>\n",
       "      <td>3614</td>\n",
       "      <td>58</td>\n",
       "      <td>789</td>\n",
       "      <td>0.924577</td>\n",
       "      <td>0.474000</td>\n",
       "      <td>0.883715</td>\n",
       "      <td>0.922391</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>enron_1_mail_3270</th>\n",
       "      <td>749</td>\n",
       "      <td>3594</td>\n",
       "      <td>78</td>\n",
       "      <td>751</td>\n",
       "      <td>0.905683</td>\n",
       "      <td>0.499333</td>\n",
       "      <td>0.748286</td>\n",
       "      <td>0.903849</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>enron_1_mail_2068</th>\n",
       "      <td>1454</td>\n",
       "      <td>3191</td>\n",
       "      <td>481</td>\n",
       "      <td>46</td>\n",
       "      <td>0.751421</td>\n",
       "      <td>0.969333</td>\n",
       "      <td>0.732412</td>\n",
       "      <td>0.751843</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>enron_1_mail_3105</th>\n",
       "      <td>1482</td>\n",
       "      <td>3172</td>\n",
       "      <td>500</td>\n",
       "      <td>18</td>\n",
       "      <td>0.747730</td>\n",
       "      <td>0.988000</td>\n",
       "      <td>0.697496</td>\n",
       "      <td>0.748183</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>enron_1_mail_3463</th>\n",
       "      <td>1490</td>\n",
       "      <td>3162</td>\n",
       "      <td>510</td>\n",
       "      <td>10</td>\n",
       "      <td>0.745000</td>\n",
       "      <td>0.993333</td>\n",
       "      <td>0.555889</td>\n",
       "      <td>0.745465</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>enron_1_mail_889</th>\n",
       "      <td>1494</td>\n",
       "      <td>3070</td>\n",
       "      <td>602</td>\n",
       "      <td>6</td>\n",
       "      <td>0.712786</td>\n",
       "      <td>0.996000</td>\n",
       "      <td>0.063694</td>\n",
       "      <td>0.713292</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>enron_1_mail_1224</th>\n",
       "      <td>1500</td>\n",
       "      <td>2896</td>\n",
       "      <td>776</td>\n",
       "      <td>0</td>\n",
       "      <td>0.659051</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.051190</td>\n",
       "      <td>0.659612</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>enron_1_mail_2075</th>\n",
       "      <td>1500</td>\n",
       "      <td>0</td>\n",
       "      <td>3672</td>\n",
       "      <td>0</td>\n",
       "      <td>0.290023</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.290538</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                   truePositives  trueNegatives  falsePositives  \\\n",
       "_rowName                                                          \n",
       "enron_1_mail_5044            155           3672               0   \n",
       "enron_1_mail_4637            447           3661              11   \n",
       "enron_1_mail_531             492           3657              15   \n",
       "enron_1_mail_3366            501           3656              16   \n",
       "enron_1_mail_4542            643           3628              44   \n",
       "enron_1_mail_5043            711           3614              58   \n",
       "enron_1_mail_3270            749           3594              78   \n",
       "enron_1_mail_2068           1454           3191             481   \n",
       "enron_1_mail_3105           1482           3172             500   \n",
       "enron_1_mail_3463           1490           3162             510   \n",
       "enron_1_mail_889            1494           3070             602   \n",
       "enron_1_mail_1224           1500           2896             776   \n",
       "enron_1_mail_2075           1500              0            3672   \n",
       "\n",
       "                   falseNegatives  precision    recall     score      cost  \n",
       "_rowName                                                                    \n",
       "enron_1_mail_5044            1345   1.000000  0.103333  1.000000  0.978819  \n",
       "enron_1_mail_4637            1053   0.975983  0.298000  0.976489  0.970476  \n",
       "enron_1_mail_531             1008   0.970414  0.328000  0.946242  0.965698  \n",
       "enron_1_mail_3366             999   0.969052  0.334000  0.933693  0.964479  \n",
       "enron_1_mail_4542             857   0.935953  0.428667  0.888078  0.933199  \n",
       "enron_1_mail_5043             789   0.924577  0.474000  0.883715  0.922391  \n",
       "enron_1_mail_3270             751   0.905683  0.499333  0.748286  0.903849  \n",
       "enron_1_mail_2068              46   0.751421  0.969333  0.732412  0.751843  \n",
       "enron_1_mail_3105              18   0.747730  0.988000  0.697496  0.748183  \n",
       "enron_1_mail_3463              10   0.745000  0.993333  0.555889  0.745465  \n",
       "enron_1_mail_889                6   0.712786  0.996000  0.063694  0.713292  \n",
       "enron_1_mail_1224               0   0.659051  1.000000  0.051190  0.659612  \n",
       "enron_1_mail_2075               0   0.290023  1.000000  0.000000  0.290538  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mldb.query(\"\"\"\n",
    "    select \"truePositives\", \"trueNegatives\", \"falsePositives\", \"falseNegatives\", precision, recall, score,\n",
    "           enron_cost({precision, recall}) as *\n",
    "    from enron_experiment1_results_0\n",
    "    order by cost desc\n",
    "\"\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "    As you can see, the best threshold is the one where in case of doubt, everything is classified as \"ham\". This leads to 1345 spam messages in the inbox, but no ham wrongly filtered as spam. Clearly this can be improved!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TBC..."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
